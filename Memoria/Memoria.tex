%%
% Plantilla de Memoria
% Modificación de una plantilla de Latex de Nicolas Diaz para adaptarla 
% al castellano y a las necesidades de escribir informática y matemáticas.
%
% Editada por: Mario Román
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%%

%%%%%%%%%%%%%%%%%%%%%
% Thin Sectioned Essay
% LaTeX Template
% Version 1.0 (3/8/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original Author:
% Nicolas Diaz (nsdiaz@uc.cl) with extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PAQUETES Y CONFIGURACIÓN DEL DOCUMENTO
%----------------------------------------------------------------------------------------

%% Configuración del papel.
% microtype: Tipografía.
% mathpazo: Usa la fuente Palatino.
\documentclass[a4paper, 11pt]{article}
\usepackage[protrusion=true,expansion=true]{microtype}
\usepackage{mathpazo}

% Indentación de párrafos para Palatino
\setlength{\parindent}{0pt}
  \parskip=8pt
\linespread{1.05} % Change line spacing here, Palatino benefits from a slight increase by default


%% Castellano.
% noquoting: Permite uso de comillas no españolas.
% lcroman: Permite la enumeración con numerales romanos en minúscula.
% fontenc: Usa la fuente completa para que pueda copiarse correctamente del pdf.
\usepackage[spanish,es-noquoting,es-lcroman]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\selectlanguage{spanish}


%% Gráficos
\usepackage{graphicx} % Required for including pictures
\usepackage{wrapfig} % Allows in-line images
\usepackage[usenames,dvipsnames]{color} % Coloring code

% % Enlaces
\usepackage[hidelinks]{hyperref}

%% Matemáticas
\usepackage{amsmath}

% Para algoritmos
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsthm}
\input{spanishAlgorithmic.tex}

%% Bibliografía
\makeatletter
\renewcommand\@biblabel[1]{\textbf{#1.}} % Change the square brackets for each bibliography item from '[1]' to '1.'
\renewcommand{\@listI}{\itemsep=0pt} % Reduce the space between items in the itemize and enumerate environments and the bibliography


%----------------------------------------------------------------------------------------
%	TÍTULO
%----------------------------------------------------------------------------------------
% Configuraciones para el título.
% El título no debe editarse aquí.
\renewcommand{\maketitle}{
  \begin{flushright} % Center align
  {\LARGE\@title} % Increase the font size of the title
  
  \vspace{50pt} % Some vertical space between the title and author name
  
  {\large\@author} % Author name
  \\\@date % Date
  \vspace{40pt} % Some vertical space between the author block and abstract
  \end{flushright}
}

% Título
\title{\textbf{Metaheurísticas: Selección de Características}\\ % Title
P-1: Búsquedas por Trayectorias Simples} % Subtitle

\author{\textsc{Óscar Bermúdez Garrido\\
\href{http://www.github.com/oxcar103}{@oxcar103}} % Author
\\{\textit{Universidad de Granada}}} % Institution

\date{\today} % Date


%----------------------------------------------------------------------------------------
%	DOCUMENTO
%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

% Resumen (Descomentar para usarlo)
\renewcommand{\abstractname}{Resumen} % Uncomment to change the name of the abstract to something else
%\begin{abstract}
% Resumen aquí
%\end{abstract}

% Palabras clave
%\hspace*{3,6mm}\textit{Keywords:} lorem , ipsum , dolor , sit amet , lectus % Keywords
%\vspace{30pt} % Some vertical space between the abstract and first section


% Índice
{\parskip=2pt
  \tableofcontents
}
\pagebreak

%% Inicio del documento
	\section{Descripción del problema}
		

	\section{Características de las heurísticas}
		En este apartado, se describirán las características comunes empleadas para resolver
		el problema
		
		\subsection{Representación de la solución}
			Representaremos la solución como un vector de booleanos de longitud $n$, con $n$
			el número de características del problema dado, en el cuál se especifica si la
			característica $f_i$ está en la solución o no.
		
		\subsection{Función objetivo y función evaluación}
			Como función objetivo lógica para nuestro problema, se tomaría la función:
			$$tasa_{aciertos} = 100 \cdot \frac{nº\ instancias\ bien\ clasificadas}{nº\ total\ de\ instancias}$$
			
			Sin embargo, como el número total de instancias es una constante y para la máquina
			es más sencillo trabajar con valores enteros que con valores decimales, optaremos
			por maximizar la función que nos calcula el número de aciertos y los transformaremos
			en la tasa de aciertos cuando queramos evaluar el buen funcionamiento de la
			clasificación realizada sobre el conjunto de evaluación.
			
			Un pequeño esquema del funcionamiento de nuestra función de evaluación sería:

			\begin{algorithm}[H]
				\begin{algorithmic}[1]

					\REQUIRE \ \\
			        	\texttt{c\_sel}, vector de características seleccionadas\\
			        	\texttt{inst}, instancias sobre las que evaluar\\ \

			     	\STATE{\texttt{aciertos} = 0}\\
			     	\FORALL{\texttt{instancia} $\in$ \texttt{inst}}
				  		\STATE{Genera \texttt{K-NN} de \texttt{instancia[i]}}
				  		\IF{\texttt{Hay clase predominante}}
							\STATE{\text{clase\ esperada} = Clase predominante de \texttt{K-NN} de \texttt{instancia[i]}}
						\ELSE
							\STATE{\text{clase\ esperada} = Clase de \texttt{1-NN} de \texttt{instancia[i]}}
						\ENDIF
				  		
						\IF{\texttt{clase\ esperada} == Clase de \texttt{instancia[i]}}
							\STATE{\texttt{aciertos++}}
						\ENDIF
					\ENDFOR
				  
					\RETURN{aciertos}			
				\end{algorithmic}
			    \caption{Función de evaluación}
			    \label{Evaluate}

		\subsection{Comparativa}
			
			\end{algorithm}
			
			Este algoritmo tiene algunas variantes, como que si no le pasas instancia, toma la que
			usó para realizar el entrenamiento, si no le pasas vector de características seleccionadas,
			usa la que tiene almacenada y que si le pasas un entero $i$, usa el vector de características
			resultante de alternar el valor de $f_i$ de la solución almacenada.
			
			En nuestro caso, tomamos $K=3$ para realizar el KNN. Además, para el cálculo del KNN
			utilizamos el \textit{framework} que ya estaba implementado en \cite{KNN}.
		
		\subsection{Operador de vecinos}
			Para la generación de una solución vecina, basta con alterar la pertenencia de una
			característica al conjunto de características seleccionadas, y alterar el contador
			de las mismas ya que me parecía más eficiente de este modo llevar la cuenta de cuántas
			fueron escogidas. Una aproximación de sería la siguiente:
			
			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
			        	\texttt{index}, índice a cambiar\\ \

			     	\STATE{\texttt{car[index]} = \texttt{!car[index]}}\\
			  		\IF{\texttt{car[index]} == \texttt{true}}
						\STATE{Incrementamos número de características seleccionadas}
					\ELSE
						\STATE{Decrementamos número de características seleccionadas}
					\ENDIF
				\end{algorithmic}
			\caption{Generación de solución vecina}
			\label{Flip}
			\end{algorithm}
		
			Y para el caso de la generación de un vecino aleatorio, bastaría con generarlo aleatoriamente,
			invocar a la función anterior y devolver el número generado (por si fuese necesario
			para algo en el ámbito en el que se invoca la función):
		
			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
							 \

			     	\STATE{\texttt{index} = Entero Aleatorio}\\
			  		\STATE{\texttt{Flip(index)}}\\
			  		
					\RETURN{index}
				\end{algorithmic}
			\caption{Generación aleatoria de solución vecina}
			\label{Neighbour}
			\end{algorithm}
		
		\subsection{\textit{5x2-Cross Validation}}
			Para realizar la comprobación del buen funcionamiento de nuestras heurísticas, realizaremos
			una serie de particiones del conjunto de instancias que nos pasan como parámetro, algunas
			las usaremos como entrenamiento y otras como validación.
			
			En concreto, utilizaremos la conocida como \textit{5x2-Cross Validation}, que consiste en
			dividir el conjunto en dos mitades, tomar una como entrenamiento y la otra como validación,
			y luego invertir la que se usó como entrenamiento y la que se usó como validación. Este
			proceso se realiza 5 veces:
			
			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
							 \
							 
			     	\FOR{\texttt{i} $<$ \texttt{5}}
				  		\STATE{\texttt{part1} = Genera partición}
				  		\STATE{\texttt{part2} = Complementario(\texttt{part1})}

						\STATE{\texttt{Heurística.entrenar(part1)}}
						\STATE{\texttt{evaluaciones[2*i]} = \texttt{Heurística.evaluar(part2)}}
										  		
						\STATE{\texttt{Heurística.entrenar(part2)}}
						\STATE{\texttt{evaluaciones[2*i+1]} = \texttt{Heurística.evaluar(part1)}}
					\ENDFOR
					
					\RETURN{evaluciones}
				\end{algorithmic}
			\caption{\textit{5x2-Cross Validation}}
			\label{Cross-Validation}
			\end{algorithm}			
			
		\subsection{Entrada y salida}
			Para recoger los datos a través de la entrada, he implementado una clase extra basándome
			en \cite{ARFFReader}.
			Para generar los archivos \textit{.csv}, he utilizado una clase implementada por un
			compañero y algo adaptada a mi estilo de programación.

	\section{Heurísticas implementadas}
		\subsection{\textit{Sequential Forward Selection} (\textbf{SFS})}
			Para realizar la comprobación del buen funcionamiento del resto de heurísticas, realizaremos
			una heurística \textit{Greedy} que nos dé una solución para el problema de clasificación
			de características.
			
			En particular, usaremos el \textit{Sequential Forward Selection} que se encarga de ir
			seleccionando las características a añadir una por una tomando siempre la que mayor mejora
			produce hasta que ya no se produce mejora.
			
			Para la inicialización del objeto, nos basta con aportarle las instancias de entrenamiento
			y el índice de la columna de clase.
			
			El proceso de entrenamiento se puede ilustrar mediante el siguiente algoritmo:

			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
							 \

					\STATE{\texttt{hay\_mejora} = \texttt{true}}
				    \WHILE{\texttt{hay\_mejora} \AND \texttt{Número de características seleccionadas} $<$
				    		\texttt{Número de características}}
				     	\FOR{\texttt{i} $<$ \texttt{Número de características}}
							\IF{\texttt{$Característica_i$} no está seleccionada ni es de clase}
								\STATE{Guardamos \texttt{Evaluate(i)}}
							\ENDIF
							
							\IF{Es mejor que las soluciones vecinas generadas hasta ahora}
								\STATE{Guardamos el valor de la mejor}
								\STATE{Guardamos el índice de la característica mejorada}
							\ENDIF
						\ENDFOR
						
						\IF{Mejora la solución actual}
							\STATE{\texttt{Flip(índice de mejora)}}
							\STATE{Guardamos el valor de la solución actual}
						\ELSE
							\STATE{\texttt{hay\_mejora} = \texttt{false}}
						\ENDIF
					\ENDWHILE
				\end{algorithmic}
			\caption{\textit{Sequential Forward Selection}}
			\label{SFS}
			\end{algorithm}			

		\subsection{Búsqueda Local (\textbf{LS})}
			Como primera forma de búsqueda de la solución, utilizaremos la búsqueda local del primero
			mejor. Ésta consiste en:
				\begin{enumerate}
					\item Generar una solución inicial aleatoria\footnote{Aunque en nuestro caso, esto
					se hace en la inicialización del objeto.}.
					\item Tras esto, generamos una serie de vecinos aleatorios.
					\item Aceptamos el primero que mejore la solución actual.
					\item Si generamos un número determinado\footnote{En nuestro código, este número
					consiste en 1.5 $\cdot$ número de características de los datos para dar posibilidad
					a que se prueben todas las características aunque no lo comprobamos.} de vecinos y
					no se ha mejorado, acabamos.
				\end{enumerate}

			Para la inicialización del objeto, nos basta con aportarle las instancias de entrenamiento,
			el índice de la columna de clase y una semilla, pues requiere de un generador de números
			aleatorios para su correcto funcionamiento.

			El algoritmo de su función de entrenamiento sería algo así:
			
			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
							 \

					\STATE{Hacemos copia de la solución actual y el número de características seleccionadas}
					\STATE{\texttt{evaluación\_actual} = Evaluate()}
					
					\WHILE{Iteraciones sin mejora < 1.5 $\cdot$ Número de características
							\OR Se exceda el número máximo de evaluaciones}
				     	\STATE{\texttt{índice} = GenerateNeighbour()}
				     	
				     	\IF{Mejora evaluación actual}
				     		\STATE{Hacemos copia de esta solución y el número de características seleccionadas}
				     		\STATE{Iteraciones sin mejora = 0}
				     	\ELSE
				     		\STATE{Restauramos valores de la solución actual}
				     		\STATE{Incrementamos el número de iteraciones sin mejora}
				     	\ENDIF
					\ENDWHILE
				\end{algorithmic}
			\caption{Búsqueda Local}
			\label{LS}
			\end{algorithm}			

		\subsection{Enfriamiento Simulado (\textbf{SA})}
			Para enfriamiento simulado, es necesario el uso de ciertas variables:
			\begin{itemize}
				\item $\sigma = 0.3$, probabilidad de aceptar una solución peor que la actual.
				\item $\mu = 0.3$, coeficiente que regula cómo de mala puede ser una solución peor
				aceptada.
				\item $T_0$ $\equiv$ Temperatura inicial = $\mu$ $\cdot$ Valor de la solución inicial / $\ln(\sigma)$,
				temperatura a la que comenzamos.
				\item $T_f$ $ \equiv$ Temperatura final = $10^{-3}$, cuando se alcance esta temperatura, se parará la
				búsqueda.
				\item Vecinos máximos = 10 $\cdot$ Número de características, que indica cuántos vecinos
				se pueden generar antes de que se produzca un enfriamiento.
				\item Éxitos máximos = 0.1 $\cdot$ Vecinos máximos $\equiv$ Número de características,
				que indica cuántos éxitos se pueden tener antes de que se produzca un enfriamiento.
				\item M $\equiv$ Número de Enfriamientos = Número máximo de evaluaciones / Vecinos máximos,
				establece cuántas veces se enfriará entre la temperatura inicial y la final
				\item $\displaystyle beta = \frac{T_0 - T_f}{M \cdot T_0 \cdot T_f}$
			\end{itemize}

			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
							 \
							 
				  	\STATE{$\displaystyle Temperatura = \frac{Temperatura}{1 + \beta * \texttt{Temperatura}}$}
				\end{algorithmic}
			\caption{Enfriamiento Simulado - Enfriamiento}
			\label{SA-Annealing}
			\end{algorithm}

			\begin{algorithm}[H]
				\begin{algorithmic}[1]
					\REQUIRE \ \\
						\texttt{eval\_act}, evaluación actual \\
						\texttt{eval\_asp}, evaluación candidata \\ \
							 
					\STATE{\texttt{Aceptar} = \texttt{true}}
				  	\IF{Empeora la solución}
				  		\STATE{\texttt{rnd} = Genera valor aleatorio entre 0 y 1}

				  		\STATE{$\displaystyle \texttt{exponente} = \frac{eval\_act - eval\_asp}{T}$}
				  		\IF{\texttt{rnd} > $e^{exponente}$}
				  			\STATE{\texttt{Aceptar} = \texttt{false}}
				  		\ENDIF
				  	\ENDIF
				  	
				  	\RETURN{Aceptar}
				\end{algorithmic}
			\caption{Enfriamiento Simulado - Criterio de metrópolis}
			\label{SA-mCrit}
			\end{algorithm}

		\subsection{Búsqueda Tabú (\textbf{TS})}
			
	\section{Resultados}
		\subsection{\textit{Sequential Forward Selection} (\textbf{SFS})}
			\input{WDBC-SFS}
			\input{MLIB-SFS}
			\input{ARRH-SFS}
		
		\subsection{Búsqueda Local (\textbf{LS})}
			\input{WDBC-LS}
			\input{MLIB-LS}
			\input{ARRH-LS}

		\subsection{Enfriamiento Simulado (\textbf{SA})}
			\input{WDBC-SA}
			\input{MLIB-SA}
			\input{ARRH-SA}
		
		\subsection{Búsqueda Tabú (\textbf{TS})}
			\input{WDBC-TS}
			\input{MLIB-TS}
			\input{ARRH-TS}
			
		\subsection{Comparación de resultados}
			\input{Compare}
			
			Viendo los resultados de arriba, podemos concluir que:
			\begin{itemize}
				\item Los mayores índices de reducción se obtienen con el \textit{SFS}, obteniendo en
				todos los casos una tasa de reducción superior al 80\% y los demás, rondan el 50\%.
				Lo que nos hace pensar que puede ser que los demás tenga sobre-ajuste sobre los datos
				de entrenamiento.
				
				\item En el caso de \textit{WBDC}, todos los algoritmos tienen una alta tasa de acierto,
				quizás la mejor heurística en este caso, sería utilizar \textit{LS} ya que, a pesar
				de que \textit{TS} tienen un valor mayor, su coste en tiempo desproporcional lo descarta
				rápidamente.
				
				\item En el caso de \textit{Movement Libras}, optaría por tomar \textit{SA} por motivos
				similares al caso anterior: aunque no sea el que posee el mayor índice de acierto,
				\textit{TS} lo descartamos por excesivo tiempo de ejecución, tiene un gran índice de
				acierto, un índice de reducción aceptable y se ejecuta en un tiempo razonable.

				\item Sin duda alguna, para el caso de \textit{Arrhythmia}, el mejor algoritmo sería
				el de \textit{SFS}, ya que tiene el mejor índice de acierto(con un único valor muy
				bajo en las 10 iteraciones que provoca una bajada importante en la media), de reducción
				y un tiempo bastante bajo para la cantidad de características e instancias que tiene.
			\end{itemize}
		
	\newpage
	
	\begin{thebibliography}{10}
	\expandafter\ifx\csname url\endcsname\relax
	  \def\url#1{\texttt{#1}}\fi
	\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
	\expandafter\ifx\csname href\endcsname\relax
	  \def\href#1#2{#2} \def\path#1{#1}\fi
	
	\bibitem{KNN}
	WEKA (The University of Waikato)\\
	  \url{http://weka.sourceforge.net/doc.dev/weka/classifiers/lazy/IBk.html}\\
	  \url{http://weka.sourceforge.net/doc.dev/weka/core/neighboursearch/NearestNeighbourSearch.html}
	  
  	\bibitem{ARFFReader}
  	WEKA (The University of Waikato)\\
	  \url{http://weka.sourceforge.net/doc.dev/weka/core/converters/ArffLoader.ArffReader.html}
	  
	\end{thebibliography}

\end{document}
